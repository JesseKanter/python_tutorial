{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction_cats_dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "w9ZjgYEKtUDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Explainable deep-learning -- Visualizing deep neural networks\n",
        "\n",
        "## [Author: Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan)\n",
        "### CEO and Chief Imagination Officer, [Moad Computer](https://moad.computer)\n",
        "\n",
        "## [Launch this notebook in Google CoLab](https://colab.research.google.com/github/rahulremanan/python_tutorial/blob/master/Machine_Vision/02_Object_Prediction/notebook/prediction_cats_dogs.ipynb)\n",
        "\n",
        "\n",
        "This is a skeletal frame work for building better explainable deep-learning.\n",
        "\n",
        "In this notebook, using the [Kaggle Dogs vs Cats Redux, Kernels Edition dataset](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)."
      ]
    },
    {
      "metadata": {
        "id": "3LhELpJYSeWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "metadata": {
        "id": "9A1K9U8rQrb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tqdm\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import model_from_json\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import UpSampling2D, Conv2D\n",
        "from keras.preprocessing import image\n",
        "#from keras.applications.inception_resnet_v2 import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaeVC3zPQrct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_timestamp():\n",
        "    timestring = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "    print (\"Time stamp generated: \"+timestring)\n",
        "    return timestring"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RN5bZAdNQrc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def is_valid_file(parser, arg):\n",
        "    if not os.path.isfile(arg):\n",
        "        parser.error(\"The file %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbz8dNb5QrdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def is_valid_dir(parser, arg):\n",
        "    if not os.path.isdir(arg):\n",
        "        parser.error(\"The folder %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTm00Q79OKJZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to load the model for generating predictions"
      ]
    },
    {
      "metadata": {
        "id": "vIOamQNiQrdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_prediction_model(args):\n",
        "    try:\n",
        "        print (args.config_file[0]) \n",
        "        with open(args.config_file[0]) as json_file:\n",
        "              model_json = json_file.read()\n",
        "        model = model_from_json(model_json)\n",
        "    except:\n",
        "          print (\"Please specify a model configuration file ...\")\n",
        "          sys.exit(1)\n",
        "    try:\n",
        "          model.load_weights(args.weights_file[0])\n",
        "          print (\"Loaded model weights from: \" + str(args.weights_file[0]))\n",
        "    except:\n",
        "          print (\"Error loading model weights ...\")\n",
        "          sys.exit(1)\n",
        "    try:\n",
        "        print (args.labels_file[0])\n",
        "        with open(args.labels_file[0]) as json_file:\n",
        "            labels = json.load(json_file)\n",
        "        print (\"Loaded labels from: \" + str(args.labels_file[0]))\n",
        "    except:\n",
        "        print (\"No labels loaded ...\")\n",
        "        sys.exit(1)\n",
        "    return model, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQBOXHpgN55p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to generate predictions"
      ]
    },
    {
      "metadata": {
        "id": "2UHBCOJdQrdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(model, img, target_size):\n",
        "  print (\"Running prediction model on the image file ...\")\n",
        "  if img.size != target_size:\n",
        "    img = img.resize(target_size)\n",
        "\n",
        "  _x_ = image.img_to_array(img)\n",
        "  _x_ = np.expand_dims(_x_, axis=0)\n",
        "  _x_ = preprocess_input(_x_)\n",
        "  preds = model.predict(_x_)\n",
        "  probabilities = model.predict(_x_, batch_size=1).flatten()\n",
        "  prediction = labels[np.argmax(probabilities)]\n",
        "  return preds[0], prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "abkjc4jqOAd5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to plot prediction accuracy"
      ]
    },
    {
      "metadata": {
        "id": "Lo_2HiqDQrdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_preds(image, preds, labels, timestr):\n",
        "  output_loc = args.output_dir[0]\n",
        "  output_file_preds = os.path.join(output_loc+\"//preds_out_\"+timestr+\".png\")\n",
        "  fig = plt.figure()\n",
        "  plt.axis('on')\n",
        "  labels = labels\n",
        "  plt.barh([0, 1], preds, alpha=0.5)\n",
        "  plt.yticks([0, 1], labels)\n",
        "  plt.xlabel('Probability')\n",
        "  plt.xlim(0,1.01)\n",
        "  plt.tight_layout()\n",
        "  fig.savefig(output_file_preds, dpi=fig.dpi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZGYHacNPynL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize parameters for generating predictions"
      ]
    },
    {
      "metadata": {
        "id": "A5HzdgOlQrd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import types\n",
        "args=types.SimpleNamespace()\n",
        "args.config_file = ['./trained_cats_dogs.config']\n",
        "args.weights_file = ['./trained_cats_dogs_epochs30_weights.model']\n",
        "args.labels_file = ['./trained_labels.json']\n",
        "args.output_dir = ['./']\n",
        "args.image = ['./cat_01.jpg']\n",
        "args.image_url = ['https://github.com/rahulremanan/python_tutorial/raw/master/Machine_Vision/02_Object_Prediction/test_images/dog_01.jpg']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jpk8UxY3P4-6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the trained deep learning model and load model weights"
      ]
    },
    {
      "metadata": {
        "id": "cot1Qt6QQreM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model, labels = load_prediction_model(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keYSL1qANWb6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualizing the model architecture -- Inception version 3"
      ]
    },
    {
      "metadata": {
        "id": "GrMTEIO_gL7K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model \n",
        "import pydot \n",
        "import graphviz # apt-get install -y graphviz libgraphviz-dev && pip3 install pydot graphviz \n",
        "from IPython.display import SVG \n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRaqMqfFgS9H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_dir = './'\n",
        "plot_model(model, to_file= output_dir + '/model_summary_plot.png') \n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nThPS8SxPLJz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [Download model weights, configuration, classification labels](https://github.com/rahulremanan/python_tutorial/tree/master/Machine_Vision/02_Object_Prediction/model) [and example images](https://github.com/rahulremanan/python_tutorial/tree/master/Machine_Vision/02_Object_Prediction/test_images)"
      ]
    },
    {
      "metadata": {
        "id": "MG5JwL-2ihro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/rahulremanan/python_tutorial/master/Machine_Vision/02_Object_Prediction/test_images/cat_01.jpg -O cat_01.jpg\n",
        "! wget https://raw.githubusercontent.com/rahulremanan/python_tutorial/master/Machine_Vision/02_Object_Prediction/model/trained_cats_dogs.config -O trained_cats_dogs.config\n",
        "! wget https://raw.githubusercontent.com/rahulremanan/python_tutorial/master/Machine_Vision/02_Object_Prediction/model/trained_labels.json -O trained_labels.json\n",
        "! wget https://media.githubusercontent.com/media/rahulremanan/python_tutorial/master/Machine_Vision/02_Object_Prediction/model/trained_cats_dogs_epochs30_weights.model -O trained_cats_dogs_epochs30_weights.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CTQFr-N5SyWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Specify input size for the image to generate predictions"
      ]
    },
    {
      "metadata": {
        "id": "ZRASsNssQrcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_size = (299, 299) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3J5o7woINhpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating predictions and plotting classification accuracy"
      ]
    },
    {
      "metadata": {
        "id": "IIDIIYsRQjtX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test image 1"
      ]
    },
    {
      "metadata": {
        "id": "Dn3xBGe8Qo_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize input image"
      ]
    },
    {
      "metadata": {
        "id": "VHicA2vFQree",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image as PyImage\n",
        "from IPython.core.display import HTML \n",
        "PyImage(args.image[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mq4NMN9zQreq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if args.image is not None:\n",
        "    img = Image.open(args.image[0])\n",
        "    preds = predict(model, img, target_size)\n",
        "    print (preds[1] + \"\\t\" + \"\\t\".join(map(lambda x: \"%.2f\" % x, preds[0])))\n",
        "    print (str(preds[1]))\n",
        "    timestr = generate_timestamp()\n",
        "    plot_preds(img, preds[0], labels, timestr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BWcdpmvwQre1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path_pred1 = os.path.join('./preds_out_'+timestr+'.png')\n",
        "PyImage(image_path_pred1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ky9tSGRfWoCY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test image 2"
      ]
    },
    {
      "metadata": {
        "id": "tEqsToTYQrfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PyImage(url = args.image_url[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBKf0aCWQrfT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if args.image_url is not None:\n",
        "    response = requests.get(args.image_url[0])\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    preds = predict(model, img, target_size)\n",
        "    print (preds[1] + \"\\t\" + \"\\t\".join(map(lambda x: \"%.2f\" % x, preds[0])))\n",
        "    print (str(preds[1]))\n",
        "    timestr = generate_timestamp()\n",
        "    plot_preds(img, preds[0], labels, timestr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eTN6oQjtQrfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path_pred2 = os.path.join('./preds_out_'+timestr+'.png')\n",
        "PyImage(image_path_pred2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRC4MJvtgUav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def class_activation_map(INPUT_IMG_FILE=None,\n",
        "                         PRE_PROCESSOR=None,\n",
        "                         LABEL_DECODER=None,\n",
        "                         MODEL=None,\n",
        "                         LABELS=None,\n",
        "                         IM_WIDTH=299,\n",
        "                         IM_HEIGHT=299,\n",
        "                         CONV_LAYER='conv_7b',\n",
        "                         URL_MODE=False,\n",
        "                         FILE_MODE=False,\n",
        "                         EVAL_STEPS=1,\n",
        "                         HEATMAP_SHAPE=[8,8],\n",
        "                         BENCHMARK=True):\n",
        "  \n",
        "  if INPUT_IMG_FILE == None:\n",
        "    print ('No input file specified to generate predictions ...')\n",
        "    return\n",
        "  \n",
        "  if URL_MODE:\n",
        "    response = requests.get(INPUT_IMG_FILE)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = img.resize((IM_WIDTH, IM_HEIGHT))\n",
        "  elif FILE_MODE:\n",
        "    img = INPUT_IMG_FILE\n",
        "  else:\n",
        "    img = image.load_img(INPUT_IMG_FILE, target_size=(IM_WIDTH, IM_HEIGHT))\n",
        "    \n",
        "  x = img\n",
        "  \n",
        "  if not FILE_MODE:\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    if PRE_PROCESSOR !=None:\n",
        "      preprocess_input = PRE_PROCESSOR\n",
        "      x = preprocess_input(x)\n",
        "  \n",
        "  model = MODEL\n",
        "  if model == None:\n",
        "    print ('No input model specified to generate predictions ...')\n",
        "    return\n",
        "  labels = LABELS\n",
        "  \n",
        "  heatmaps = []\n",
        "  heatmap_sum = np.empty(HEATMAP_SHAPE, float)\n",
        "  \n",
        "  last_conv_layer = model.get_layer(CONV_LAYER)  \n",
        "  feature_size = tensor_featureSizeExtractor(last_conv_layer)\n",
        "  \n",
        "  model_input = model.input\n",
        "  model_output = model.output\n",
        "  last_conv_layer_out = last_conv_layer.output\n",
        "  \n",
        "  iterate_input = []\n",
        "  \n",
        "  pred_labels = []\n",
        "  out_labels = []\n",
        "  \n",
        "  probabilities = np.empty((0,len(labels)), float)\n",
        "  \n",
        "  for step in (range(EVAL_STEPS)):\n",
        "    \n",
        "    startTime = time.time()\n",
        "    \n",
        "    preds = model.predict(x, batch_size=1)\n",
        "    \n",
        "    preds_endTime = time.time()\n",
        "    \n",
        "    \n",
        "    probability = preds.flatten()\n",
        "    \n",
        "\n",
        "    probabilities = np.append(probabilities, \n",
        "                              np.array([probability]), \n",
        "                              axis=0)\n",
        "    \n",
        "    if labels !=None:\n",
        "      pred_label = labels[np.argmax(probability)]\n",
        "      pred_labels.append(pred_label)\n",
        "      out_labels.append(pred_label)\n",
        "      print('PREDICTION: {}'.format(pred_label))\n",
        "      print('ACCURACY: {}'.format(preds[0]))\n",
        "      del pred_label\n",
        "    elif LABEL_DECODER !=None:\n",
        "      pred_label = pd.DataFrame(LABEL_DECODER(preds, top=3)[0],columns=['col1','category','probability']).iloc[:,1:]\n",
        "      pred_labels.append(pred_label.loc[0,'category'])\n",
        "      out_labels.append(pred_label.loc[0,'category'])\n",
        "      print('PREDICTION:',pred_label.loc[0,'category'])\n",
        "      del pred_label\n",
        "    else:\n",
        "      print ('No labels will be generated ...')\n",
        "      \n",
        "    pred_labels = set(pred_labels)\n",
        "    pred_labels = list(pred_labels)\n",
        "  \n",
        "    argmax = np.argmax(probability)\n",
        "    \n",
        "    heatmap_startTime = time.time()\n",
        "  \n",
        "    output = model_output[:, argmax]\n",
        "    \n",
        "    model_endTime = time.time()  \n",
        "  \n",
        "    grads = K.gradients(output, \n",
        "                        last_conv_layer_out)[0]\n",
        "    pooled_grads = K.mean(grads, \n",
        "                          axis=(0, 1, 2))\n",
        "      \n",
        "    iterate = K.function([model_input], [pooled_grads,\n",
        "                                         last_conv_layer_out[0]])\n",
        "    \n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "    \n",
        "    grad_endTime = time.time()\n",
        "    \n",
        "    for i in range(feature_size):\n",
        "      conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
        "      \n",
        "    iter_endTime = time.time()\n",
        "    \n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    \n",
        "    heatmap_endTime = time.time()  \n",
        "    \n",
        "    try:\n",
        "      heatmap_sum = np.add(heatmap_sum, heatmap)\n",
        "      heatmaps.append(heatmap)\n",
        "      if EVAL_STEPS >1:\n",
        "        del probability\n",
        "        del heatmap\n",
        "        del output\n",
        "        del grads\n",
        "        del pooled_grads\n",
        "        del iterate\n",
        "        del pooled_grads_value\n",
        "        del conv_layer_output_value\n",
        "    except:\n",
        "      print ('Failed updating heatmaps ...')\n",
        "    \n",
        "    endTime = time.time()\n",
        "    \n",
        "    predsTime = preds_endTime - startTime\n",
        "    gradsTime = grad_endTime - model_endTime\n",
        "    iterTime = iter_endTime - grad_endTime\n",
        "    heatmapTime = heatmap_endTime - heatmap_startTime\n",
        "    executionTime = endTime - startTime\n",
        "    model_outputTime = model_endTime - heatmap_startTime\n",
        "    \n",
        "    if BENCHMARK:\n",
        "      print ('Heatmap generation time: {} seconds ...'. format(heatmapTime))\n",
        "      print ('Gradient generation time: {} seconds ...'.format(gradsTime))\n",
        "      print ('Iteration loop execution time: {} seconds ...'.format(iterTime))\n",
        "      print ('Model output generation time: {} seconds'.format(model_outputTime))\n",
        "      print ('Prediction generation time: {} seconds ...'.format(predsTime))\n",
        "      print ('Completed processing {} out of {} steps in {} seconds ...'.format(int(step+1), int(EVAL_STEPS), float(executionTime)))\n",
        "    \n",
        "  if EVAL_STEPS >1:\n",
        "    mean_heatmap = heatmap_sum/EVAL_STEPS\n",
        "  else:\n",
        "    mean_heatmap = heatmap\n",
        "    \n",
        "  mean = np.matrix.mean(np.asmatrix(probabilities), axis=0)\n",
        "  stdev = np.matrix.std(np.asmatrix(probabilities), axis=0)\n",
        "  \n",
        "  accuracy = np.matrix.tolist(mean)[0][np.argmax(mean)]\n",
        "  uncertainty = np.matrix.tolist(stdev)[0][np.argmax(mean)]\n",
        "  \n",
        "  return [mean_heatmap, accuracy, uncertainty, pred_labels, heatmaps, out_labels, probabilities]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "58gbAjgphDav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels_json='./trained_labels.json'\n",
        "with open(labels_json) as json_file:\n",
        "  labels = json.load(json_file)\n",
        "print (labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDgW8ox_kc_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PRE_PROCESSOR = preprocess_input\n",
        "MODEL = model\n",
        "INPUT_IMG_FILE = './cat_01.jpg'\n",
        "LABELS= labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OruhDSpdhLQQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pL2jAyQuhQ5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img=mpimg.imread(INPUT_IMG_FILE)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJ-Bel3PhVvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ziIhegJhZ1k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tensor_featureSizeExtractor(last_conv_layer):\n",
        "  if len(last_conv_layer.output.get_shape().as_list()) == 4:\n",
        "    feature_size = last_conv_layer.output.get_shape().as_list()[3]\n",
        "    return feature_size\n",
        "  else:\n",
        "    return 'Received tensor shape: {} instead of expected shape: 4'.format(len(last_conv_layer.output.get_shape().as_list()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TrFKAPfuhg0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def heatmap_overlay(INPUT_IMG_FILE,\n",
        "                    HEATMAP,\n",
        "                    THRESHOLD=0.8):\n",
        "  img = cv2.imread(INPUT_IMG_FILE)\n",
        "  \n",
        "  heatmap = cv2.resize(HEATMAP, (img.shape[1], img.shape[0]))\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  hif = THRESHOLD\n",
        "  superimposed_img = heatmap * hif + img\n",
        "  return [superimposed_img, heatmap]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQw6PNmthqfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = class_activation_map(INPUT_IMG_FILE=INPUT_IMG_FILE,\n",
        "                              PRE_PROCESSOR=PRE_PROCESSOR,\n",
        "                              MODEL=MODEL,\n",
        "                              LABELS=LABELS,\n",
        "                              IM_WIDTH=299,\n",
        "                              IM_HEIGHT=299,\n",
        "                              CONV_LAYER='mixed10')\n",
        "HEATMAP = output[0]\n",
        "\n",
        "plt.matshow(HEATMAP)\n",
        "plt.show()\n",
        "print (output[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qs9Je6xWhs3z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "heatmap_output = heatmap_overlay(INPUT_IMG_FILE,\n",
        "                                 HEATMAP,\n",
        "                                 THRESHOLD=0.8)\n",
        "superimposed_img = heatmap_output[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrnUAP6ph5XP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_file = './class_activation_map.jpeg'\n",
        "cv2.imwrite(output_file, superimposed_img)\n",
        "\n",
        "img=mpimg.imread(output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJ5jhwQKh9W6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-88xP0J_lMuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}