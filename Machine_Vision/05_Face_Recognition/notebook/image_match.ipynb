{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection, tracking and matching:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import basename\n",
    "import glob\n",
    "import sys\n",
    "import types\n",
    "import subprocess\n",
    "from random import randint\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV version check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "if int(major_ver)  < 3 :\n",
    "    print (\"Update OpenCV ...\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load video files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './Kanye_West-Gold_Digger_ft__Jamie_Foxx.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    video_capture = cv2.VideoCapture(source)\n",
    "    print (\"Imported video using OpenCV ...\")\n",
    "except:\n",
    "    video_capture =  skvideo.io.vread(source)\n",
    "    print (\"Imported video using sci-kit video ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables for video processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-7, decay=0.5, momentum=1, nesterov=True)\n",
    "rms = RMSprop(lr=1e-7, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "ada = Adagrad(lr=1e-7, epsilon=1e-08, decay=0.0)\n",
    "optimizer = sgd\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./proc_vid.mp4\"\n",
    "save_audio = \"./audio.wav\"\n",
    "save_path_w_audio = \"./proc_vid_audio.mp4\"\n",
    "output_dir = './output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "frame_number = 0\n",
    "face_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = int(video_capture.get(3)),int(video_capture.get(4))\n",
    "print (\"Source image width: \"+ str(w))\n",
    "print (\"Source image height: \"+ str(h))\n",
    "\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter(save_path, fourcc, fps, (w,h), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image_path = \"./ref_img/\"\n",
    "file_list = glob.glob(reference_image_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc_frames = length\n",
    "resize_img = False\n",
    "verbose = True\n",
    "gen_train_img = True\n",
    "interleaved = False\n",
    "use_deep_learning = False\n",
    "annotate = False\n",
    "process_this_frame = True\n",
    "inverse_scale_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_model(args):\n",
    "    try:\n",
    "        with open(args.config_file[0]) as json_file:\n",
    "              model_json = json_file.read()\n",
    "        model = model_from_json(model_json)\n",
    "    except:\n",
    "          print (\"Please specify a model configuration file ...\")\n",
    "          sys.exit(1)\n",
    "    try:\n",
    "          model.load_weights(args.weights_file[0])\n",
    "          print (\"Loaded model weights from: \" + str(args.weights_file[0]))\n",
    "    except:\n",
    "          print (\"Error loading model weights ...\")\n",
    "          sys.exit(1)\n",
    "    try:\n",
    "        with open(args.labels_file[0]) as json_file:\n",
    "            labels = json.load(json_file)\n",
    "        print (\"Loaded labels from: \" + str(args.labels_file[0]))\n",
    "    except:\n",
    "        print (\"No labels loaded ...\")\n",
    "        sys.exit(1)\n",
    "    return model, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_predict(model):\n",
    "    try:\n",
    "        compile_model(model)\n",
    "        print (\"Model successfully compiled ...\")\n",
    "    except:\n",
    "        print (\"Model failed to compile ...\")\n",
    "\n",
    "    print (\"Compiling predictor function ...\")                                          # to avoid the delay during video capture.\n",
    "    _ = model.predict(np.zeros((1, n, n, 3), dtype=np.float32), batch_size=1)\n",
    "    print (\"Compilation completed ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = types.SimpleNamespace()\n",
    "args.config_file = ['./model/trained_2018_02_27-20_09_00_config_ft_.json']\n",
    "args.weights_file = ['./model/trained_2018_02_27-20_09_00_weights_ft_.model']\n",
    "args.labels_file = ['./model/trained_labels.json']\n",
    "args.output_dir = ['./output/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, labels = load_prediction_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OpenCV using: [interpolation = cv2.INTER_CUBIC](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#resize) argument in cv2.resize, performs a bi-cubic interpolation over 4x4 pixel neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (video_capture.isOpened()):    \n",
    "    ret, frame = video_capture.read() # Grab a single frame of video\n",
    "    \n",
    "    frame_number += 1\n",
    "    \n",
    "    if resize_img ==True:\n",
    "        isf = inverse_scale_factor\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=(1/isf), fy=(1/isf)) # Resize frame of video to 1/inverse_scale_factor size for faster processing\n",
    "    else:\n",
    "        isf = 1\n",
    "        small_frame = frame\n",
    "    if frame_number <=n_proc_frames:\n",
    "        if ret ==True:\n",
    "            if process_this_frame:\n",
    "                face_locations = face_recognition.face_locations(small_frame) # Find all the faces and face encodings in the current frame of video\n",
    "                face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "                face_names = []\n",
    "                if annotate == True or gen_train_img == True:\n",
    "                    for face_encoding in face_encodings:\n",
    "                        for file_path in file_list:\n",
    "                            reference_image = face_recognition.load_image_file(file_path)\n",
    "                            try:\n",
    "                                reference_face_encoding = face_recognition.face_encodings(reference_image)[0]\n",
    "                                if verbose == True:\n",
    "                                    print (\"Processed face encodings ...\")\n",
    "                                else:\n",
    "                                    pass\n",
    "                            except:\n",
    "                                if verbose == True:\n",
    "                                    print(\"Failed processing face encodings ...\")\n",
    "                                else:\n",
    "                                    pass\n",
    "                            if annotate == True:\n",
    "                                name_ID = (os.path.splitext(basename(file_path))[0])\n",
    "                                name_ID = name_ID.replace(\"_\", \" \")\n",
    "                                match = face_recognition.compare_faces([reference_face_encoding], face_encoding) # See if the face is a match for the known face(s)\n",
    "                                name = \"Unknown\"\n",
    "                                if match[0]:\n",
    "                                    name = name_ID\n",
    "                                face_names.append(name)\n",
    "                            else:\n",
    "                                pass\n",
    "                else:\n",
    "                    if verbose == True:\n",
    "                        print (\"Skipping face recognition mode ...\")\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print (\"Skipping frame ...\")\n",
    "                else:\n",
    "                    pass\n",
    "            if interleaved == True:\n",
    "                process_this_frame = not process_this_frame # Only process every other frame of video to save time\n",
    "            else:\n",
    "                process_this_frame = process_this_frame\n",
    "\n",
    "            # Display the results\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                # Scale back up face locations since the frame we detected in was scaled to scaling factor size\n",
    "                top *= int(isf)\n",
    "                right *= int(isf)\n",
    "                bottom *= int(isf)\n",
    "                left *= int(isf)\n",
    "                # Draw an ellipse around the face\n",
    "                ex = left\n",
    "                ey = top\n",
    "                ew = int(abs(right - ex))\n",
    "                eh = int(abs(bottom - ey))\n",
    "                p1 = int(ew/2 + ex)\n",
    "                p2 = int(eh/2 + ey)\n",
    "                h1 = int(ew/2)\n",
    "                h2 = int(eh/2)\n",
    "                square = frame[max((ey-eh//2,0)):ey+3*eh//2, max((ex-ew//2,0)):ex+3*ew//2]\n",
    "                if gen_train_img == True:\n",
    "                    random_number = randint(10000000, 99999999)\n",
    "                    random_number = str(random_number)\n",
    "                    cv2.imwrite(os.path.join(output_dir+\"//\"+str(random_number)+\"frame_%d.jpg\" % face_count), square)\n",
    "                    if verbose == True:\n",
    "                        print (\"Saved frame: \"+ str(face_count)+\" with face detected ...\" )\n",
    "                    else:\n",
    "                        pass\n",
    "                    face_count += 1\n",
    "                else:\n",
    "                    pass\n",
    "                cv2.ellipse(frame, (p1, p2), (h1,h2), 0,0,360, (0,255,0), 2)\n",
    "                if use_deep_learning == True and annotate == True:\n",
    "                    square = cv2.resize(square.astype(np.float32),    \\\n",
    "                                        dsize=(IMG_WIDTH, IMG_HEIGHT),\\\n",
    "                                        interpolation = cv2.INTER_CUBIC)\n",
    "                    try:\n",
    "                        _X_ = image.img_to_array(square)\n",
    "                        del (square)\n",
    "                        _X_ = np.expand_dims(_X_, axis=0)\n",
    "                        _X_ = preprocess_input(_X_)\n",
    "                        probabilities = model.predict(_X_, batch_size=1).flatten()\n",
    "                        del (_X_)\n",
    "                        prediction = labels[np.argmax(probabilities)]\n",
    "                        name = (str(prediction)).replace(\"_\", \" \")\n",
    "                        print (\"Face recognition using deep-learning ...\")\n",
    "                        print (prediction + \"\\t\" + \"\\t\".join(map(lambda x: \"%.2f\" % x, probabilities)))\n",
    "                        print (str(prediction))\n",
    "                        del (prediction)\n",
    "                    except:\n",
    "                        print (\"Failed to create a prediction ...\")         \n",
    "                else:\n",
    "                    pass\n",
    "                if annotate == True:\n",
    "                    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                    cv2.rectangle(frame, (p1 - 100, bottom - 2), (p1 + 100, bottom + 33), (0, 0, 255), cv2.FILLED) \n",
    "                    cv2.putText(frame, name, (p1  - 94, bottom + 23 ), font, 0.75, (255, 255, 255), 1) # Draw a label with a name below the face\n",
    "                else:\n",
    "                    if verbose == True:\n",
    "                        print (\"No identifiers to annotate. Try setting annotate flag to True ...\")\n",
    "                    else:\n",
    "                        pass\n",
    "            try:\n",
    "                video_writer.write(frame)\n",
    "                if verbose == True:\n",
    "                    print(\"Processed frame {} / {}\".format(frame_number, length))\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                if verbose == True:\n",
    "                    print(\"Failed writing frame {} / {}\".format(frame_number, length))\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            if verbose == True:\n",
    "                print(\"No frame to process ...\")\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        if verbose == True:\n",
    "            print (\"Processed \"+ str(n_proc_frames) + \" frames\")\n",
    "            print (\"Detected \" + str(face_count) + \" faces\" )\n",
    "        else:\n",
    "            print (\"Detected \" + str(face_count) + \" faces\" )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release handle reading the video file or webcam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract audio from a video file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'ffmpeg -i %s -ab 320000 -ac 2 -ar 44100 -vn %s' % (source, save_audio)\n",
    "print (cmd)\n",
    "subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy audio track from one video to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'ffmpeg -y -i %s -i %s -shortest -c:v copy -c:a aac -b:a 256k  %s' % (save_path, save_audio, save_path_w_audio)\n",
    "print (cmd)\n",
    "subprocess.call(cmd, shell=True)\n",
    "print('Muxing completed ...')\n",
    "print('Saved output file to: %s' % (save_path_w_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize deep-learning model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model \n",
    "import pydot \n",
    "import graphviz # apt-get install -y graphviz libgraphviz-dev \n",
    "from IPython.display import SVG \n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file= os.path.join(args.output_dir[0] + '/model_face_detection.png')) \n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
