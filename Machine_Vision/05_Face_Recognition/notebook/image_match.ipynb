{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "from os.path import basename\n",
    "import skvideo.io\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "if int(major_ver)  < 3 :\n",
    "    print (\"Update OpenCV ...\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './Drag_Me_Down.mp4'\n",
    "try:\n",
    "    video_capture = cv2.VideoCapture(source)\n",
    "    print (\"Imported video using Open-CV ...\")\n",
    "except:\n",
    "    video_capture =  skvideo.io.vread(source)\n",
    "    print (\"Imported video using sci-kit video ...\")\n",
    "    \n",
    "length = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "save_path = \"./proc_vid.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "frame_number = 0\n",
    "process_this_frame = True\n",
    "inverse_scale_factor = 2\n",
    "\n",
    "w, h = int(video_capture.get(3)),int(video_capture.get(4))\n",
    "\n",
    "print (\"Source image width: \"+ str(w))\n",
    "print (\"Source image height: \"+ str(h))\n",
    "\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter(save_path, fourcc, fps, (w,h), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image_path = \"./ref_img/\"\n",
    "file_list = glob.glob(reference_image_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_proc_frames = length\n",
    "resize_img = False\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (video_capture.isOpened()):\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    frame_number += 1\n",
    "       \n",
    "    if resize_img ==True:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        isf = inverse_scale_factor\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=(1/isf), fy=(1/isf))\n",
    "    else:\n",
    "        isf = 1\n",
    "        small_frame = frame\n",
    "    # Only process every other frame of video to save time\n",
    "    if frame_number <=n_proc_frames:\n",
    "        if ret ==True:\n",
    "            if process_this_frame:\n",
    "                # Find all the faces and face encodings in the current frame of video\n",
    "                face_locations = face_recognition.face_locations(small_frame)\n",
    "                face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "\n",
    "                face_names = []\n",
    "                for face_encoding in face_encodings:\n",
    "                    for file_path in file_list:\n",
    "                        reference_image = face_recognition.load_image_file(file_path)\n",
    "                        try:\n",
    "                            reference_face_encoding = face_recognition.face_encodings(reference_image)[0]\n",
    "                            if verbose == True:\n",
    "                                print (\"Processed face encodings ...\")\n",
    "                            else:\n",
    "                                pass\n",
    "                        except:\n",
    "                            if verbose == True:\n",
    "                                print(\"Failed processing face encodings ...\")\n",
    "                            else:\n",
    "                                pass\n",
    "                        name_ID = (os.path.splitext(basename(file_path))[0])\n",
    "                        name_ID = name_ID.replace(\"_\", \" \")\n",
    "                        # See if the face is a match for the known face(s)\n",
    "                        match = face_recognition.compare_faces([reference_face_encoding], face_encoding)\n",
    "                        name = \"Unknown\"\n",
    "                    \n",
    "                        if match[0]:\n",
    "                            name = name_ID\n",
    "\n",
    "                        face_names.append(name)\n",
    "\n",
    "            process_this_frame = not process_this_frame\n",
    "\n",
    "            # Display the results\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "                top *= int(isf)\n",
    "                right *= int(isf)\n",
    "                bottom *= int(isf)\n",
    "                left *= int(isf)\n",
    "                # Draw an ellipse around the face\n",
    "                ex = left\n",
    "                ey = top\n",
    "                ew = int(abs(right - ex))\n",
    "                eh = int(abs(bottom - ey))\n",
    "                p1 = int(ew/2 + ex)\n",
    "                p2 = int(eh/2 + ey)\n",
    "                h1 = int(ew/2)\n",
    "                h2 = int(eh/2)\n",
    "                cv2.ellipse(frame, (p1, p2), (h1,h2), 0,0,360, (0,255,0), 2)\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame, (p1 - 100, bottom - 2), (p1 + 100, bottom + 33), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (p1  - 94, bottom + 23 ), font, 0.75, (255, 255, 255), 1)\n",
    "        \n",
    "            try:\n",
    "                video_writer.write(frame)\n",
    "                print(\"Processed frame {} / {}\".format(frame_number, length))\n",
    "            except:\n",
    "                print(\"Failed writing frame {} / {}\".format(frame_number, length))\n",
    "    else:\n",
    "        print (\"Processed \"+ str(n_proc_frames) + \" frames\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release handle to read the video file or webcam\n",
    "video_capture.release()\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
