-- Update and upgrade --

$ sudo apt-get update
$ sudo apt-get upgrade

-- Verify CUDA capability --

$ sudo apt-get install pciutils 
$ lspci | grep -i nvidia

-- Verify linux version support --

$ uname -m && cat /etc/*release

-- Install dependencies --

$ sudo apt-get install -y build-essential dkms freeglut3 freeglut3-dev libxi-dev libxmu-dev cmake git unzip zip pylint pkg-config g++ zlib1g-dev python python3-numpy python3-dev python3-pip python3-wheel

-- Install linux kernel header --

$ uname -r
$ sudo apt-get install linux-headers-$(uname -r)

-- Fetch CUDA 10 installer file --

$ wget -O cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64

-- Fetch installer --

$ sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb

-- Add keys -- 

## Recommended method ##

$ sudo apt-key add /var/cuda-repo-10-0-local-10.0.130-410.48/7fa2af80.pub

-- Or --

$ sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub

-- Install CUDA --

$ sudo apt-get update
$ sudo apt-get -y install cuda

-- Verify CUDA installation --

echo 'export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc
source ~/.bashrc
ldconfig
nvidia-smi

-- Install TesnorRT 5.0 --
(https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html)

Download tensorrt installer from https://developer.nvidia.com/nvidia-tensorrt-5x-download

$ sudo dpkg -i nv-tensorrt-repo-ubuntu1804-cuda10.0-trt5.0.0.10-rc-20180906_1-1_amd64.deb
$ sudo apt-key add /var/nv-tensorrt-repo-cuda10.0-trt5.0.0.10-rc-20180906/7fa2af80.pub

$ sudo apt-get update
$ sudo apt-get install -y tensorrt

$ sudo apt-get install -y python3-libnvinfer-dev uff-converter-tf

-- Verify TensorRT installation --

$ dpkg -l | grep TensorRT

-- Install cuDNN 7.3.1 --

Download cuDNN from: https://developer.nvidia.com/cudnn

$ tar -xf ./cudnn-10.0-linux-x64-v7.3.1.20.tgz
$ sudo cp -R cuda/include/* /usr/local/cuda-10.0/include
$ sudo cp -R cuda/lib64/* /usr/local/cuda-10.0/lib64

-- Install NCCL 2.3.5 --

Download os agnostic nccl from: https://developer.nvidia.com/nccl 

$ tar -xf nccl_2.3.5-2+cuda10.0_x86_64.txz 
$ mkdir /usr/local/cuda-10.0/lib/
$ mkdir /usr/local/cuda-10.0/include/
$ cd /nccl_2.3.5-2+cuda10.0_x86_64/
$ sudo cp -R ./lib/* /usr/local/cuda-10.0/lib/
$ sudo cp -R ./include/* /usr/local/cuda-10.0/include/
$ sudo ldconfig

$ mv ./LICENCE.txt ./NCCL-SLA.txt

$ sudo cp ./NCCL-SLA.txt /usr/local/cuda-10.0

-- Install lincupti --

$ sudo apt-get install -y libcupti-dev
$ echo 'export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc

-- Install tensorflow dependencies--

$ sudo pip3 install keras_applications --no-deps keras_preprocessing --no-deps h5py scipy matplotlib

-- Install bazel --

$ cd ~/
$ wget https://github.com/bazelbuild/bazel/releases/download/0.17.2/bazel-0.17.2-installer-darwin-x86_64.sh
$ chmod +x bazel-0.17.2-installer-darwin-x86_64.sh
$ sudo ./bazel-0.17.2-installer-darwin-x86_64.sh
$ echo 'export PATH="$PATH:$HOME/bin"' >> ~/.bashrc

$ source ~/.bashrc
$ sudo ldconfig

-- Test bazel --

whereis bazel

-- Install bazel from apt repository --

$ sudo apt-get install openjdk-8-jdk

$ echo "deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list
$ curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -

$ sudo apt-get update && sudo apt-get install -y bazel

$ sudo apt-get upgrade bazel

-- Removing bazel --

$ rm $HOME/.cache/bazel -fr
$ sudo rm /usr/local/bin/bazel /etc/bazelrc /usr/local/lib/bazel -fr

-- Fetch and configure tensorflow --

$ cd ~/
$ git clone https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
$ git pull
$ git checkout

-- For a specific tensorflow version --

$ git checkout r1.11

$ ./configure

-- Sample configuration --
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:
  /usr/lib/python3.6/dist-packages
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.6/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3.6/dist-packages]

Do you wish to build TensorFlow with Apache Ignite support? [Y/n]: 
Apache Ignite support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 10.0


Please specify the location where CUDA 10.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-10.0


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 7.3.1


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-10.0]: 


Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Please specify the location where TensorRT is installed. [Default is /usr/lib/x86_64-linux-gnu]:


Please specify the NCCL version you want to use. If NCCL 2.2 is not installed, then you can use version 1.3 that can be fetched automatically but it may have worse performance with multiple GPUs. [Default is 2.2]: 2.3.5


NCCL libraries found in /usr/local/cuda-10.0/targets/x86_64-linux/lib/libnccl.so
Assuming NCCL header path is /usr/local/cuda-10.0/targets/x86_64-linux/lib/../include
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.0]: 6.0

Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: 
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=gdr            # Build with GDR support.
        --config=verbs          # Build with libverbs support.
        --config=ngraph         # Build with Intel nGraph support.
Configuration finished

-- Build tensorflow using bazel --

$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

add "--config=mkl" (For Intel MKL support for newer intel cpu for faster training on cpu)
add "--config=monolithic" (For static monolithic build. Try this option if a build fails.)
add "--local_resources 2048,.5,1.0" (For devices with low ram causing Segmentation fault or other related errors.)

-- Build tensorflow using bazel for Intel Haswell using CUDA 10 --

$ sudo bazel build -c opt --copt=-march="haswell" --config=cuda //tensorflow/tools/pip_package:build_pip_package

-- Build python wheel installer --

$ sudo bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
$ sudo pip3 install /tmp/tensorflow_pkg/tensorflow-*.whl

-- Setup tensorflow for Julia --

$ bazel build --config=opt //tensorflow:libtensorflow.so --config=cuda

-- Copy libtensorflow.so to julia packages folder --

$ cd ./bazel-bin/tensorflow
$ sudo su
$ mkdir /etc/tensorflow/
$ cp ./libtensorflow.so /etc/tensorflow/
$ cp ./libtensorflow_framework.so /etc/tensorflow/

--Setup a virtual environment --

$ sudo apt-get install virtualenv
$ virtualenv tf_1.11.0_cuda10.0 -p /usr/bin/python3
$ source tf_1.11.0_cuda10.0/bin/activate
$ pip install ./tmp/tensorflow_pkg/tensorflow*.whl

-- Verify tensorflow installation --

$ python
(Run this inside python interpreter)
>>>import tensorflow as tf
>>>hello = tf.constant('Hello, TensorFlow!')
>>>sess = tf.Session()
>>>print(tf.__version__)
>>>print(sess.run(hello))

-- Keras installation --

$ git clone https://github.com/keras-team/keras.git
$ cd keras
$ sudo python3 setup.py install
$ python3 -c "import keras"